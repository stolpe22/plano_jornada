# Scraper e Enriquecedor de Plano de Estudos da Jornada de Dados

Este projeto Ã© uma aplicaÃ§Ã£o web construÃ­da com **Streamlit** que automatiza duas tarefas principais:

- **Web Scraping:** Autentica-se na plataforma Jornada de Dados e extrai uma lista completa de todas as trilhas, cursos, mÃ³dulos e aulas disponÃ­veis, incluindo o slug para gerar links diretos e o status de conclusÃ£o de cada aula.
- **Enriquecimento de Dados:** Utiliza um arquivo CSV com um plano de estudos fornecido pelo usuÃ¡rio e, atravÃ©s de correspondÃªncia difusa (fuzzy matching), associa cada mÃ³dulo do plano ao seu link correspondente e status de conclusÃ£o, exportando um novo CSV com os dados enriquecidos.
- **ExploraÃ§Ã£o Interativa:** Permite filtrar, buscar e navegar de forma dinÃ¢mica por todo o conteÃºdo raspado, inclusive com busca fuzzy, filtragem por trilha e visualizaÃ§Ã£o de relevÃ¢ncia dos resultados.

O objetivo Ã© transformar um plano de estudos estÃ¡tico numa ferramenta de navegaÃ§Ã£o dinÃ¢mica, facilitando o acesso direto ao conteÃºdo da plataforma e o acompanhamento do progresso.

---

## âœ¨ Funcionalidades

- **Interface Web Simples:** Uma interface amigÃ¡vel criada com Streamlit que guia o usuÃ¡rio pelo processo de scraping, junÃ§Ã£o de dados e exploraÃ§Ã£o dos cursos.
- **AutenticaÃ§Ã£o Segura:** O usuÃ¡rio insere suas credenciais, que sÃ£o usadas para criar uma sessÃ£o autenticada para o scraping dos dados.
- **Scraping Concorrente:** Utiliza multithreading para acelerar o processo de busca pelos detalhes das aulas, fazendo mÃºltiplas requisiÃ§Ãµes em paralelo.
- **Status de ConclusÃ£o:** O scraper coleta o status de conclusÃ£o de cada aula diretamente da plataforma.
- **JunÃ§Ã£o Inteligente de Dados:** Emprega a biblioteca `thefuzz` para fazer a correspondÃªncia entre os nomes dos mÃ³dulos/cursos no plano de estudos e os nomes extraÃ­dos da plataforma, mesmo que nÃ£o sejam idÃªnticos.
- **Dashboard e Busca Fuzzy:** Visualize seu progresso geral, filtre por trilha, busque por termos aproximados (inclusive com erros de digitaÃ§Ã£o) e navegue diretamente para cada aula.
- **RelevÃ¢ncia dos Resultados:** A busca mostra o score de relevÃ¢ncia de cada resultado.
- **ExportaÃ§Ã£o de Resultados:** Gera um arquivo CSV final com o plano de estudos original enriquecido com colunas de link da aula e status de conclusÃ£o.

---

## ğŸ“‚ Estrutura do Projeto

```
PLANO_JORNADA/
â”‚
â”œâ”€â”€ dados/
â”‚   â”œâ”€â”€ plano_de_estudos.csv              # INPUT: Seu plano de estudos.
â”‚   â”œâ”€â”€ cursos_jornada.csv                # OUTPUT: Gerado pelo scraper.
â”‚   â”œâ”€â”€ plano_de_estudos_com_links.csv    # OUTPUT: O resultado final com links e status.
â”‚
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ authenticator.py                  # AutenticaÃ§Ã£o na plataforma.
â”‚   â”œâ”€â”€ scraper.py                        # LÃ³gica completa de scraping.
â”‚   â”œâ”€â”€ data_joiner.py                    # JunÃ§Ã£o e enriquecimento dos dados via fuzzy matching.
â”‚
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 1_scraper_page.py                 # PÃ¡gina Streamlit para scraping e junÃ§Ã£o.
â”‚   â”œâ”€â”€ 2_dashboard_page.py               # PÃ¡gina Streamlit para visualizaÃ§Ã£o do progresso.
â”‚   â”œâ”€â”€ 3_jornada_courses_page.py         # NOVA: PÃ¡gina Streamlit para exploraÃ§Ã£o de cursos e busca fuzzy.
â”œâ”€â”€ app.py                                # PÃ¡gina inicial da aplicaÃ§Ã£o Streamlit.
â”œâ”€â”€ requirements.txt                      # Lista de dependÃªncias do projeto.
â”œâ”€â”€ README.md                             # Este arquivo.
â”œâ”€â”€ .gitignore
```

---

## ğŸš€ Como Configurar e Executar

Siga os passos abaixo para executar o projeto localmente.

### 1. PrÃ©-requisitos

- Python 3.8 ou superior.

### 2. InstalaÃ§Ã£o

Clone este repositÃ³rio e crie um ambiente virtual:

```bash
# Criar ambiente virtual
python -m venv .venv

# Ativar o ambiente virtual (Windows)
.venv\Scripts\activate

# Ativar o ambiente virtual (macOS/Linux)
source .venv/bin/activate
```

Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

### 3. Preparar o Plano de Estudos

- Crie a pasta `dados` na raiz do projeto, caso nÃ£o exista.
- Coloque o seu arquivo CSV de plano de estudos como `plano_de_estudos.csv` dentro da pasta `dados`.
- O CSV deve ter pelo menos as colunas **Trilha** e **MÃ³dulo** (ou equivalentes).

### 4. Executar a AplicaÃ§Ã£o

Com o ambiente virtual ativado, rode:

```bash
streamlit run app.py
```

A interface abrirÃ¡ no navegador.

---

## ğŸ“– Como Usar

A aplicaÃ§Ã£o estÃ¡ dividida em vÃ¡rias pÃ¡ginas principais na barra lateral do Streamlit:

### 1. Scraper & JunÃ§Ã£o

- Insira seu e-mail e senha da plataforma Jornada de Dados.
- Clique em **"Fazer Scraping Agora"** para coletar todos os dados de cursos, mÃ³dulos e aulas, incluindo links e status de conclusÃ£o.
- ApÃ³s o scraping, clique em **"Gerar Links no Plano de Estudos"** para fazer a junÃ§Ã£o entre seu plano e os dados coletados, gerando o arquivo enriquecido `plano_de_estudos_com_links.csv`.

### 3. Dashboard Plano de Estudos

- Visualize seu progresso geral e por trilha.
- Veja mÃ©tricas, barras de progresso e uma tabela interativa com links diretos para cada aula. Ã‰ possÃ­vel marcar aulas como concluÃ­das diretamente pela interface.

### 3. ExploraÃ§Ã£o dos Cursos (Busca Fuzzy)

- Acesse a pÃ¡gina **"Explorador de Cursos da Jornada"**.
- Filtre por trilha, busque por termos (inclusive aproximados, com tolerÃ¢ncia a erros de digitaÃ§Ã£o), e ajuste a sensibilidade da busca fuzzy.
- Veja o score de relevÃ¢ncia, acesse links diretos para as aulas, visualize sumÃ¡rio e conteÃºdo completo, e marque aulas como concluÃ­das.
- A busca utiliza tanto correspondÃªncia por frase quanto por aproximaÃ§Ã£o de palavra para garantir os melhores resultados.

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Streamlit:** Interface web interativa.
- **Requests & BeautifulSoup4:** ComunicaÃ§Ã£o HTTP e parsing do HTML.
- **Pandas:** ManipulaÃ§Ã£o de dados e geraÃ§Ã£o dos CSVs.
- **TheFuzz (FuzzyWuzzy):** CorrespondÃªncia difusa de texto.
- **Concurrent.futures:** Multithreading para acelerar scraping.
- **Os, Json:** Utilidades para manipulaÃ§Ã£o de arquivos e dados.

---

## ğŸ‘¨â€ğŸ’» ContribuiÃ§Ã£o

Pull requests sÃ£o bem-vindos! Sinta-se Ã  vontade para abrir issues ou sugerir melhorias.

---

## ğŸ“ ObservaÃ§Ãµes

- O scraper pode demorar alguns minutos, dependendo da quantidade de cursos e mÃ³dulos.
- Certifique-se que seu plano estÃ¡ padronizado para melhores resultados na correspondÃªncia.
- O status de conclusÃ£o das aulas Ã© extraÃ­do diretamente da plataforma, permitindo acompanhamento do progresso.
- A exploraÃ§Ã£o dos cursos permite busca inteligente, Ãºtil para encontrar conteÃºdos mesmo com nomes nÃ£o exatos ou erros comuns de digitaÃ§Ã£o.

---